{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f063e76b-6935-4949-a1f7-7e024b7726a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      " 10  oceano              20640 non-null  int64  \n",
      "dtypes: float64(9), int64(1), object(1)\n",
      "memory usage: 1.7+ MB\n",
      "None\n",
      "ocean_proximity\n",
      "<1H OCEAN     9136\n",
      "INLAND        6551\n",
      "NEAR OCEAN    2658\n",
      "NEAR BAY      2290\n",
      "ISLAND           5\n",
      "Name: count, dtype: int64\n",
      "oceano\n",
      "1    11794\n",
      "0     8846\n",
      "Name: count, dtype: int64\n",
      "El intercepto es = 0.377\n",
      "El coeficiente es = 0.895\n",
      "[1]\n",
      "Pr(oceano = 0|median_housing_value = 250000) = 0.3294 , \n",
      "Pr(oceano = 1|median_housing_value = 250000) = 0.6706 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jvanfran\\AppData\\Local\\Temp\\ipykernel_13876\\2688902737.py:68: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "C:\\Users\\Jvanfran\\AppData\\Local\\Temp\\ipykernel_13876\\2688902737.py:70: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n"
     ]
    }
   ],
   "source": [
    "#EJERCICIO 1\n",
    "# cargar librerias-----------------------------------------------\n",
    "import pandas as pd\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from pandas.core.common import flatten\n",
    "from plotnine import *\n",
    "from array import *\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "from tabulate import tabulate\n",
    "# definir las rutas y caminos donde se encuentran los datos------\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "# path que se va a crear en nuestro sistema----------------------\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "# lugar de descarga del dataset----------------------------------\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "# definir una funcion que obtenga los datos y los descargue-----\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, \n",
    "housing_path=HOUSING_PATH):\n",
    "    if not os.path.isdir(housing_path):\n",
    "        os.makedirs(housing_path)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "fetch_housing_data()\n",
    "# definir una funcion que cargue el csv en un dataframe----------\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "housing = load_housing_data()\n",
    "housing['oceano'] = [1 if x == '<1H OCEAN' else \n",
    "                     1 if x == 'NEAR OCEAN' else \n",
    "                     0 for x in housing['ocean_proximity']] \n",
    "# comprobacion de la variable oceano-----------------------------\n",
    "print(housing.info())\n",
    "print(housing[\"ocean_proximity\"].value_counts())\n",
    "print(housing[\"oceano\"].value_counts())\n",
    "# importar clase-------------------------------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# importar estandarizador-.--------------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#definir variable respuesta\n",
    "x = housing[\"median_house_value\"].values.reshape(-1,1)\n",
    "# estandarizamos x-----------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x_prepared = scaler.transform(x)\n",
    "# separar variable respuesta del dataset-------------------------\n",
    "y = housing[\"oceano\"].values.reshape(-1,1).ravel()\n",
    "# ajustar el modelo----------------------------------------------\n",
    "logistic_reg = LogisticRegression()\n",
    "logistic_reg.fit(x_prepared, y)\n",
    "# obtener coeficientes del modelo--------------------------------\n",
    "# intercepto\n",
    "print(\"El intercepto es = %.3f\" % logistic_reg.intercept_)\n",
    "# coeficientes de regresion\n",
    "print(\"El coeficiente es = %.3f\" % logistic_reg.coef_)\n",
    "# predecir clase-------------------------------------------------\n",
    "x_nueva = [[250000]]\n",
    "# estandarizamos la observacion\n",
    "x_nueva_prepared = scaler.transform(x_nueva)\n",
    "# predecir nueva casa--------------------------------------------\n",
    "clase_predicha = logistic_reg.predict(x_nueva_prepared)\n",
    "print(clase_predicha)\n",
    "# calcular probabilidad------------------------------------------\n",
    "clase_predicha_prob =logistic_reg.predict_proba(x_nueva_prepared)\n",
    "# sacar por pantalla las probabilidades de 0 y de 1--------------\n",
    "print(\"Pr(oceano = 0|median_housing_value = 250000) = %.4f\" % clase_predicha_prob[0,0],\",\", \n",
    "\"\\nPr(oceano = 1|median_housing_value = 250000) = %.4f\" % clase_predicha_prob[0,1],\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82299d99-ffbc-4c3d-926f-5739803510b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El intercepto es [0.40640537]\n",
      "Variable              Coeficiente\n",
      "------------------  -------------\n",
      "housing_median_age     -0.0732381\n",
      "total_rooms            -2.01059\n",
      "total_bedrooms          0.167547\n",
      "population              1.37391\n",
      "households              0.472922\n",
      "median_income           0.0478714\n",
      "median_house_value      1.17594\n",
      "[[ 0.50539419 -0.29142558  1.09671839 -0.19910795  1.04744666  3.22634352\n",
      "   0.37388967]]\n",
      "[1]\n",
      "Pr(oceano = 0|housing_new) = 0.1240 , \n",
      "Pr(oceano = 1|housing_new) = 0.8760 .\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO 2\n",
    "# CONSTRUIR MATRIZ X---------------------------------------------\n",
    "# quitar variable ocean_proximity--------------------------------\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "housing_num = housing_num.drop(\"oceano\", axis=1)\n",
    "housing_num = housing_num.drop(\"longitude\", axis=1)\n",
    "housing_num = housing_num.drop(\"latitude\", axis=1)\n",
    "# importar el \"imputador\"----------------------------------------\n",
    "from sklearn.impute import SimpleImputer\n",
    "# importar el \"estandarizador\"-----------------------------------\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# importar la clase pipeline\"------------------------------------\n",
    "from sklearn.pipeline import Pipeline\n",
    "# definir el pipeline--------------------------------------------\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputador\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "    ])\n",
    "# aplicar el pipeline--------------------------------------------\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "# importar clases------------------------------------------------\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# atributos de las variables numericas---------------------------\n",
    "num_attribs = list(housing_num)\n",
    "# definir full pipeline------------------------------------------\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs)\n",
    "    ])\n",
    "housing_prepared = full_pipeline.fit_transform(housing_num)\n",
    "\n",
    "# definir matriz X\n",
    "X = housing_prepared\n",
    "# separar variable respuesta del dataset-------------------------\n",
    "y = housing[\"oceano\"].values.reshape(-1,1).ravel()\n",
    "# ajustar el modelo----------------------------------------------\n",
    "logistic_reg_m = LogisticRegression()\n",
    "logistic_reg_m.fit(X, y)\n",
    "# obtener coeficientes del modelo--------------------------------\n",
    "# intercepto\n",
    "print(\"El intercepto es\", logistic_reg_m.intercept_)\n",
    "# coeficientes de regresion\n",
    "# print(\"Los coeficientes de las variables:\", \n",
    "# list(housing_num.columns.values.tolist()) ,  \"son:\", \n",
    "# logistic_reg_m.coef_)\n",
    "# podemos poner en una tabla estos valores-----------------------\n",
    "# poner nombres de las variables en una lista--------------------\n",
    "variables = housing_num.columns.values.tolist()\n",
    "# poner los coeficientes en otra lista---------------------------\n",
    "coefs = logistic_reg_m.coef_.tolist()[0]\n",
    "# definir las filas de la tabla----------------------------------\n",
    "table = zip(variables, coefs)\n",
    "# imprimir las tablas con nombres de las columnas (headers)------\n",
    "print(tabulate(table, headers = [\"Variable\", \"Coeficiente\"]))\n",
    "# obtener observacion--------------------------------------------\n",
    "housing_new = pd.DataFrame(np.array([[35, 2000, 1000, 1200, 900,\n",
    "10, 250000]]), columns = variables)\n",
    "# estandarizar---------------------------------------------------\n",
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(housing_num)\n",
    "housing_new_prepared = scaler2.transform(housing_new)\n",
    "# valor estandarizado--------------------------------------------\n",
    "print(housing_new_prepared)\n",
    "# predecir clase------------------------------------------\n",
    "clase_predicha=logistic_reg_m.predict(housing_new_prepared)\n",
    "print(clase_predicha)\n",
    "# calcular probabilidad------------------------------------------\n",
    "clase_predicha_prob=logistic_reg_m.predict_proba(housing_new_prepared)\n",
    "# sacar por pantalla las probabilidades de 0 y de 1--------------\n",
    "print(\"Pr(oceano = 0|housing_new) = %.4f\" % clase_predicha_prob[0,0],\n",
    "\",\",\"\\nPr(oceano = 1|housing_new) = %.4f\" % clase_predicha_prob[0,1],\n",
    "\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9af148-edf2-4116-bbdd-2fcb7337ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   median_house_value  20640 non-null  float64\n",
      " 1   total_rooms         20640 non-null  float64\n",
      " 2   oceano              20640 non-null  object \n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 483.9+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clase\n",
      "1    7301\n",
      "0    2900\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clase\n",
      "1    6592\n",
      "0    3609\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\software\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but KNeighborsClassifier was fitted without feature names\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clase\n",
      "1    7573\n",
      "0    2628\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#EJERCICIO 3\n",
    "#seleccionar predictores-----------------------------------------\n",
    "predictores = housing_num[[\"median_house_value\",\n",
    "\"total_rooms\"]]\n",
    "# pegar la clase a la base con los predictores estandarizados----\n",
    "puntos = predictores.copy()\n",
    "puntos[\"oceano\"] = housing[[\"oceano\"]]\n",
    "puntos[\"oceano\"] = puntos[\"oceano\"].astype(object)\n",
    "\n",
    "puntos.head()\n",
    "puntos.info()\n",
    "# pintar la clase------------------------------------------------\n",
    "(\n",
    "    ggplot(puntos, aes(x = \"median_house_value\", \n",
    "    y = \"total_rooms\", fill = \"oceano\")) +\n",
    "    geom_point() +\n",
    "    ylab(\"X2\") +\n",
    "    xlab(\"X1\") +\n",
    "    theme_bw() +\n",
    "    theme(legend_position = \"right\",\n",
    "subplots_adjust={'right': 0.8})\n",
    ")\n",
    "# estandarizar predictores---------------------------------------\n",
    "scaler3 = StandardScaler()\n",
    "scaler3.fit(predictores)\n",
    "predictores_prepared = scaler3.transform(predictores)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# crear modelo con K = 10----------------------------------------\n",
    "model_KNN_10 = KNeighborsClassifier(n_neighbors = 10)\n",
    "# utilizamos un modelo donde usamos todos los puntos-------------\n",
    "model_KNN_10.fit(predictores_prepared, y)\n",
    "# definimos una rejilla de puntos\n",
    "# valores de x1\n",
    "min_x1 = min(predictores_prepared[:,0])\n",
    "max_x1 = max(predictores_prepared[:,0])\n",
    "x1_values = np.linspace(min_x1, max_x1, 101)\n",
    "# valores de x2\n",
    "min_x2 = min(predictores_prepared[:,1])\n",
    "max_x2 = max(predictores_prepared[:,1])\n",
    "x2_values = np.linspace(min_x2, max_x2, 101)\n",
    "\n",
    "x1_grid, x2_grid =  np.meshgrid(x1_values, x2_values)  \n",
    "x1_grid = x1_grid.flatten()\n",
    "x2_grid = x2_grid.flatten() \n",
    "x_grid = pd.DataFrame({'x1':x1_grid, 'x2':x2_grid})\n",
    "\n",
    "# tipos----------------------------------------------------------\n",
    "pred_10 = model_KNN_10.predict(x_grid)\n",
    "\n",
    "regiones_10 = x_grid.copy()\n",
    "# pegar los tipos predichos a la rejilla-------------------------\n",
    "regiones_10[\"clase\"] = pred_10\n",
    "regiones_10[\"clase\"] = regiones_10[\"clase\"].astype(object)\n",
    "# ver cuantos hay de cada en la rejilla\n",
    "print(regiones_10[\"clase\"].value_counts())\n",
    "\n",
    "# pintar la rejilla----------------------------------------------\n",
    "(\n",
    "    ggplot(regiones_10, aes(\n",
    "    x = \"x1\", \n",
    "    y = \"x2\",\n",
    "    fill = \"clase\")) +\n",
    "    geom_point(size = 1) +\n",
    "    ylab(\"X2\") +\n",
    "    xlab(\"X1\") +\n",
    "    theme_bw() +\n",
    "    theme(legend_position = \"right\",\n",
    "subplots_adjust={'right': 0.8})\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# crear modelo con K = 10----------------------------------------\n",
    "model_KNN_1 = KNeighborsClassifier(n_neighbors = 1)\n",
    "# utilizamos un modelo donde usamos todos los puntos-------------\n",
    "model_KNN_1.fit(predictores_prepared, y)\n",
    "\n",
    "# tipos----------------------------------------------------------\n",
    "pred_1 = model_KNN_1.predict(x_grid)\n",
    "\n",
    "regiones_1 = x_grid.copy()\n",
    "# pegar los tipos predichos a la rejilla-------------------------\n",
    "regiones_1[\"clase\"] = pred_1\n",
    "regiones_1[\"clase\"] = regiones_1[\"clase\"].astype(object)\n",
    "print(regiones_1[\"clase\"].value_counts())\n",
    "\n",
    "# pintar la rejilla----------------------------------------------\n",
    "(\n",
    "    ggplot(regiones_1, aes(\n",
    "    x = \"x1\", \n",
    "    y = \"x2\",\n",
    "    fill = \"clase\")) +\n",
    "    geom_point(size = 1) +\n",
    "    ylab(\"X2\") +\n",
    "    xlab(\"X1\") +\n",
    "    theme_bw() +\n",
    "    theme(legend_position = \"right\",\n",
    "subplots_adjust={'right': 0.8})\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# crear modelo con K = 10----------------------------------------\n",
    "model_KNN_100 = KNeighborsClassifier(n_neighbors = 100)\n",
    "# utilizamos un modelo donde usamos todos los puntos-------------\n",
    "model_KNN_100.fit(predictores_prepared, y)\n",
    "\n",
    "# tipos----------------------------------------------------------\n",
    "pred_100 = model_KNN_100.predict(x_grid)\n",
    "\n",
    "regiones_100 = x_grid.copy()\n",
    "# pegar los tipos predichos a la rejilla-------------------------\n",
    "regiones_100[\"clase\"] = pred_100\n",
    "regiones_100[\"clase\"] = regiones_100[\"clase\"].astype(object)\n",
    "print(regiones_100[\"clase\"].value_counts())\n",
    "\n",
    "# pintar la rejilla----------------------------------------------\n",
    "(\n",
    "    ggplot(regiones_100, aes(\n",
    "    x = \"x1\", \n",
    "    y = \"x2\",\n",
    "    fill = \"clase\")) +\n",
    "    geom_point(size = 1) +\n",
    "    ylab(\"X2\") +\n",
    "    xlab(\"X1\") +\n",
    "    theme_bw() +\n",
    "    theme(legend_position = \"right\",\n",
    "subplots_adjust={'right': 0.8})\n",
    ")\n",
    "# Encontrar el valor optimo de K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# valores de K que vamos a probar--------------------------------\n",
    "k_range = range(1, 100)\n",
    "# inicializar vector de puntuaciones-----------------------------\n",
    "k_scores = []\n",
    "# bucle\n",
    "for k in k_range:\n",
    "    # ajustar el modelo con k vecinos\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # obtener puntuaciones de VC\n",
    "    scores = cross_val_score(knn, predictores_prepared, y, \n",
    "    cv = 10, scoring = \"accuracy\")\n",
    "    # Guardar puntuaciones en el vector\n",
    "    k_scores.append(scores.mean())\n",
    "# print(k_scores)\n",
    "# pintar valores-------------------------------------------------\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Valor de K para KNN')\n",
    "plt.ylabel('Accuracy de VC')\n",
    "plt.show()\n",
    "\n",
    "print(\"El valor de K que maximiza la accuracy es\", \n",
    "np.argmax(k_scores) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c3a51-e1e0-4ec2-98b4-01350d28235a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
