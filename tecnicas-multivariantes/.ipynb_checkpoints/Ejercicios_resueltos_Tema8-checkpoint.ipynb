{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4896694e-13d0-4bea-9778-076c5fccf675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar librerias-----------------------------------------------\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os  # No est√° en el pdf\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "iris = datasets.load_iris()    # loading the dataset\n",
    "\n",
    "iris.keys()\n",
    "\n",
    "iris = pd.DataFrame(\n",
    "    data = np.c_[iris['data'],\n",
    "                 iris['target']],\n",
    "    columns = iris['feature_names'] + ['target']\n",
    ")\n",
    "\n",
    "iris\n",
    "\n",
    "# cargar dataset-------------------------------------------------\n",
    "iris = load_iris()\n",
    "# seleccionar longitud y anchura del petalo----------------------\n",
    "X = iris.data[:, 2:]\n",
    "# especie de la planta\n",
    "y = iris.target\n",
    "# crear el objeto de clase arbol---------------------------------\n",
    "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=3)\n",
    "# ajustar el arbol-----------------------------------------------\n",
    "tree_clf.fit(X, y);\n",
    "\n",
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# definir donde vamos a guardar la figura------------------------\n",
    "ROOT_DIR = \".\"\n",
    "PATH_FIGURAS = os.path.join(ROOT_DIR, \"images\")\n",
    "os.makedirs(PATH_FIGURAS, exist_ok=True)\n",
    "\n",
    "export_graphviz(\n",
    "tree_clf,\n",
    "out_file = os.path.join(PATH_FIGURAS, \"arbol_iris.dot\"),\n",
    "feature_names = iris.feature_names[2:],\n",
    "class_names = iris.target_names,\n",
    "rounded = True,\n",
    "filled = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3c8a835-60c4-46ae-98db-1233897b2723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 13 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 18.2 KB\n",
      "None\n",
      "target\n",
      "1    71\n",
      "0    59\n",
      "2    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "#EJERCICIO 1\n",
    "# cargar librerias-----------------------------------------------\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine\n",
    "# cargar dataset-------------------------------------------------\n",
    "wine = load_wine(as_frame = True)\n",
    "# ver variables predictoras wine---------------------------------\n",
    "print(wine.data.info())\n",
    "# ver variable respuesta-----------------------------------------\n",
    "print(wine.target.value_counts())\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# seleccionar todas las variables--------------------------------\n",
    "X = wine.data\n",
    "# especie de la planta\n",
    "y = wine.target\n",
    "# crear el objeto de clase arbol---------------------------------\n",
    "tree_clf = DecisionTreeClassifier(random_state = 3)\n",
    "# ajustar el arbol-----------------------------------------------\n",
    "tree_clf.fit(X, y);\n",
    "# Ojo: pip install graphviz\n",
    "from graphviz import Source\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# definir donde vamos a guardar la figura------------------------\n",
    "ROOT_DIR = \".\"\n",
    "PATH_FIGURAS = os.path.join(ROOT_DIR, \"ejercicio08_images\")\n",
    "os.makedirs(PATH_FIGURAS, exist_ok=True)\n",
    "\n",
    "export_graphviz(\n",
    "        tree_clf,\n",
    "        out_file = os.path.join(PATH_FIGURAS, \"ejercicio08_arbol_wine.dot\"),\n",
    "        feature_names = wine.feature_names,\n",
    "        class_names = wine.target_names,\n",
    "        rounded = True,\n",
    "        filled = True\n",
    "    )\n",
    "# crear el objeto de clase arbol fijando profundidad maxima a 3--\n",
    "tree_clf_b = DecisionTreeClassifier(random_state=3, max_depth=3)\n",
    "# ajustar el arbol-----------------------------------------------\n",
    "tree_clf_b.fit(X, y);\n",
    "# generar el .dot------------------------------------------------\n",
    "export_graphviz(\n",
    "        tree_clf_b,\n",
    "        out_file = os.path.join(PATH_FIGURAS, \"ejercicio08_arbol_wine_b.dot\"),\n",
    "        feature_names = wine.feature_names,\n",
    "        class_names = wine.target_names,\n",
    "        rounded = True,\n",
    "        filled = True\n",
    "    )\n",
    "# crear el objeto de clase arbol fijando min_leaf a 4------------\n",
    "tree_clf_c = DecisionTreeClassifier(random_state=3, \n",
    "min_samples_leaf=4)\n",
    "# ajustar el arbol-----------------------------------------------\n",
    "tree_clf_c.fit(X, y);\n",
    "# generar el .dot------------------------------------------------\n",
    "export_graphviz(\n",
    "        tree_clf_c,\n",
    "        out_file = os.path.join(PATH_FIGURAS, \"ejercicio08_arbol_wine_c.dot\"),\n",
    "        feature_names = wine.feature_names,\n",
    "        class_names = wine.target_names,\n",
    "        rounded = True,\n",
    "        filled = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41f663c-6c8b-4b16-8504-1ff6250b6a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n",
      "0.94\n",
      "0.96\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "#EJERCICIO2\n",
    "# cargar numpy---------------------------------------------------\n",
    "import numpy as np\n",
    "# definir semilla para que la particion sea la misma-------------\n",
    "np.random.seed(3)\n",
    "# definir funcion particiones------------------------------------\n",
    "def particiones(target, dataset, test_part):\n",
    "    test_part_size = int(len(dataset) * test_part)\n",
    "    mezclar_indices = np.random.permutation(len(dataset))\n",
    "    test_indices = mezclar_indices[:test_part_size]\n",
    "    train_indices = mezclar_indices[test_part_size:]\n",
    "    return dataset.iloc[train_indices], dataset.iloc[test_indices], target.iloc[train_indices], target.iloc[test_indices]\n",
    "# usar funcion particiones con test_part 0.28---------------------\n",
    "X_train, X_test, y_train, y_test = particiones(wine.target, \n",
    "wine.data, 0.281)\n",
    "\n",
    "# cargar librerias-----------------------------------------------\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# crear objeto de la clase BaggingClassifier---------------------\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state = 3), n_estimators = 500,\n",
    "    max_samples = 75, bootstrap=True, random_state = 3);\n",
    "\n",
    "# ajustar el modelo----------------------------------------------\n",
    "bag_clf.fit(X_train, y_train);\n",
    "\n",
    "# obtener estimaciones del modelo sobre la muestra de test-------\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "# comprobar resultados-------------------------------------------\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# crear objeto de la clase BaggingClassifier---------------------\n",
    "pas_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(random_state = 3), n_estimators = 500,\n",
    "    max_samples = 75, bootstrap=False, random_state = 3);\n",
    "\n",
    "# ajustar el modelo----------------------------------------------\n",
    "pas_clf.fit(X_train, y_train);\n",
    "\n",
    "# obtener estimaciones del modelo sobre la muestra de test-------\n",
    "y_pred_pas = pas_clf.predict(X_test);\n",
    "\n",
    "# comprobar resultados-------------------------------------------\n",
    "print(accuracy_score(y_test, y_pred_pas))\n",
    "\n",
    "\n",
    "# cargar librerias-----------------------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# crear objeto de la clase RandomForestClassifier----------------\n",
    "rnd_clf = RandomForestClassifier(n_estimators = 500, \n",
    "max_leaf_nodes = 4, random_state = 3, max_samples = 75);\n",
    "\n",
    "# ajustar el modelo----------------------------------------------\n",
    "rnd_clf.fit(X_train, y_train);\n",
    "\n",
    "# obtener estimaciones del modelo sobre la muestra de test-------\n",
    "y_pred_rf = rnd_clf.predict(X_test);\n",
    "\n",
    "# comprobar resultados-------------------------------------------\n",
    "print(accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "\n",
    "# comparar con los resultados de un arbol de decision------------\n",
    "tree_clf = DecisionTreeClassifier(random_state = 3, max_depth = 3);\n",
    "tree_clf.fit(X_train, y_train);\n",
    "y_pred_tree = tree_clf.predict(X_test);\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa06bd-b1b3-46ef-b316-185c6ffdfc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n"
     ]
    }
   ],
   "source": [
    "#EJERCICIO3\n",
    "# cargar librerias-----------------------------------------------\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# crear objeto de la clase BaggingClassifier---------------------\n",
    "gb_clf = GradientBoostingClassifier(n_estimators = 500,\n",
    "random_state = 3);\n",
    "\n",
    "# ajustar el modelo----------------------------------------------\n",
    "gb_clf.fit(X_train, y_train);\n",
    "\n",
    "# obtener estimaciones del modelo sobre la muestra de test-------\n",
    "y_pred_gb = gb_clf.predict(X_test);\n",
    "\n",
    "# comprobar resultados-------------------------------------------\n",
    "print(accuracy_score(y_test, y_pred_gb))\n",
    "# crear un conjunto de posibles valores--------------------------\n",
    "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "max_depths = [1, 2, 3, 4]\n",
    "# inicializamos los vectores de resultados-----------------------\n",
    "resultados_test = []\n",
    "# bucle para extraer resultados----------------------------------\n",
    "for eta in learning_rates:\n",
    "  for d in max_depths:\n",
    "   gb_clf_i = GradientBoostingClassifier(learning_rate = eta, \n",
    "   n_estimators = 500, random_state = 3, max_depth = d);\n",
    "   # entrenamos al modelo----------------------------------------\n",
    "   gb_clf_i.fit(X_train, y_train);\n",
    "   # prediccion sobre la muestra de validacion-------------------   \n",
    "   y_pred_test = gb_clf_i.predict(X_test);\n",
    "   # accuracy de entrenamiento-----------------------------------\n",
    "   acc_test = accuracy_score(y_test, y_pred_test);\n",
    "   # guardar resultados en el vector-----------------------------\n",
    "   resultados_test.append(acc_test);\n",
    "# resultados_test[0:6] # max_depth = 1\n",
    "# resultados_test[6:12] # max_depth = 2\n",
    "# resultados_test[12:18] # max_depth = 3\n",
    "# resultados_test[18:24] # max_depth = 4\n",
    "# learning_rates\n",
    "\n",
    "# pintamos los resultados de entrenamiento y validacion----------   \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "\n",
    "plt.figure(figsize=(8, 4.75))\n",
    "\n",
    "\n",
    "line1, = plt.plot(learning_rates, resultados_test[0:6], \"b\",\n",
    "label = \"max_depth = 1\")\n",
    "line2, = plt.plot(learning_rates, resultados_test[6:12], \"r\",\n",
    "label = \"max_depth = 2\")\n",
    "line2, = plt.plot(learning_rates, resultados_test[12:18], \"g\",\n",
    "label = \"max_depth = 3\")\n",
    "line2, = plt.plot(learning_rates, resultados_test[18:24], \"y\",\n",
    "label = \"max_depth = 4\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints = 4)})\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"learning rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed82bfa6-3804-4d00-bc48-4401a5a0447a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
